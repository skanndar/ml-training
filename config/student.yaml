# Student Model Configuration
# MobileNetV2 trained via knowledge distillation from teachers

model:
  name: "mobilenetv2_100"
  pretrained: true
  alpha: 1.0  # Width multiplier
  dropout_rate: 0.2

distillation:
  # Teacher models for ensemble
  teachers:
    - path: "./results/teacher_global_v1/best_model.pt"
      weight: 0.5
      name: "teacher_global"
    - path: "./results/teacher_regional_v1/best_model.pt"
      weight: 0.5
      name: "teacher_regional"
      region_filter: "EU_SW"  # Higher weight for EU_SW samples

  # Distillation hyperparameters
  temperature: 3.0
  alpha: 0.7  # Weight for KL divergence (vs cross-entropy)

  # Soft labels source
  soft_labels_path: "./data/soft_labels_combined.npz"
  precomputed: true  # Use precomputed soft labels (faster)

training:
  # Phase 1: Distillation
  phase1:
    name: "distillation"
    epochs: 10
    learning_rate: 1.0e-4
    batch_size: 128
    loss_weights:
      kl_divergence: 0.7
      cross_entropy: 0.3

  # Phase 2: Fine-tuning with hard labels
  phase2:
    name: "finetuning"
    epochs: 10
    learning_rate: 5.0e-5
    batch_size: 128
    loss_weights:
      cross_entropy: 1.0

  # Common
  optimizer: "adam"
  weight_decay: 0.0001
  gradient_clip: 1.0
  warmup_epochs: 1

data:
  train_jsonl: "./data/dataset_train.jsonl"
  val_jsonl: "./data/dataset_val.jsonl"
  image_size: 224
  num_workers: 4

augmentation:
  train:
    resize: 256
    crop: 224
    horizontal_flip: 0.5
    rotation: 15
    color_jitter:
      brightness: 0.3
      contrast: 0.3
      saturation: 0.3
      hue: 0.1
    random_erasing: 0.2
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

  val:
    resize: 256
    center_crop: 224
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

regularization:
  dropout: 0.2
  mixup_alpha: 0.2
  cutmix_alpha: 0.2
  mixup_prob: 0.2

callbacks:
  early_stopping: true
  early_stopping_patience: 5
  early_stopping_metric: "val_loss"
  save_checkpoint_every: 1
  save_best: true
  checkpoint_metric: "val_top1_acc"

logging:
  log_every_n_steps: 100
  tensorboard: true

device:
  type: "cuda"
  mixed_precision: true

output:
  checkpoint_dir: "./checkpoints/student"
  results_dir: "./results/student_v1"

# Export configuration
export:
  formats: ["pytorch", "onnx", "tfjs"]
  quantization: "fp16"
  tfjs_output_dir: "./dist/models/student_v1.0"
