model:
  name: "mobilenetv2_100"
  pretrained: true

training:
  learning_rate: 3.0e-4
  weight_decay: 0.0001
  batch_size: 32
  grad_accum_steps: 1
  epochs: 20
  warmup_epochs: 1
  gradient_clip: 1.0
  optimizer: "adamw"
  label_smoothing: 0.0

callbacks:
  early_stopping: true
  early_stopping_patience: 3
  checkpoint_metric: "val_top1_acc"
  save_checkpoint_every: 1

logging:
  log_every_n_steps: 100

loss:
  alpha: 0.7      # peso distillation (KL)
  beta: 0.3       # peso cross-entropy (hard labels)
  temperature: 3.0

data:
  train_jsonl: "./data/dataset_train_stratified.jsonl"
  val_jsonl: "./data/dataset_val_stratified.jsonl"
  image_size: 224
  num_workers: 6
  cache_size_gb: 120
  smart_crop: false

augmentation:
  train:
    resize: 256
    crop: 224
    horizontal_flip: 0.5
    rotation: 15
    color_jitter:
      brightness: 0.2
      contrast: 0.2
      saturation: 0.2
      hue: 0.1
    blur: 0.1
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

  val:
    resize: 256
    center_crop: 224
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

soft_labels:
  path: "./data/soft_labels_combined_train.npz"
  class_mapping_json: "./data/class_mapping.json"

output:
  checkpoint_dir: "./checkpoints/student_distill"
  results_dir: "./results/student_distill_v1"
  finetune_checkpoint_dir: "./checkpoints/student_finetune"
  finetune_results_dir: "./results/student_finetune_v1"

inference:
  confidence_threshold: 0.62  # Optimized for offline-first PWA (94.5% accuracy, 80.1% coverage)
  temperature: 2.0  # Applied during calibration (ECE=0.040)

device:
  type: "cuda"
  mixed_precision: true
