# ConversiÃ³n a TF.js usando Google Colab

**Fecha:** 24 de diciembre de 2025
**Problema:** TensorFlow 2.13.1 no estÃ¡ disponible en Google Colab (solo 2.16+)
**SoluciÃ³n:** Usar versiones recientes compatibles con Colab

## Por quÃ© Google Colab

Google Colab ahora solo incluye TensorFlow 2.16+ por defecto. El paquete `tensorflowjs` es compatible con cualquier versiÃ³n de TensorFlow 2.x, asÃ­ que podemos usar la versiÃ³n ya instalada en Colab.

**Ventajas:**
- âœ… Gratis y sin instalaciÃ³n
- âœ… TensorFlow ya preinstalado
- âœ… Solo necesitas instalar `tensorflowjs`
- âœ… No requiere dependencias de compilaciÃ³n
- âœ… Funciona desde el navegador

## Instrucciones Paso a Paso

### Paso 1: Preparar el SavedModel localmente

```bash
# En tu mÃ¡quina local
cd /home/skanndar/SynologyDrive/local/aplantida/ml-training

# Comprimir el SavedModel
zip -r saved_model.zip dist/models/student_v1_fp16_manual/saved_model/

# Verificar tamaÃ±o (debe ser ~51 MB)
ls -lh saved_model.zip
```

### Paso 2: Abrir Google Colab

1. Ir a https://colab.research.google.com
2. Crear nuevo notebook: **Archivo â†’ Nuevo cuaderno**
3. Renombrar a "TFjs Conversion" (opcional)

### Paso 3: Ejecutar la conversiÃ³n

Copiar y pegar el siguiente cÃ³digo en una celda de Colab:

```python
# ==============================================================================
# INSTALACIÃ“N
# ==============================================================================

print("=== Instalando tensorflowjs ===")
!pip install -q tensorflowjs

import tensorflow as tf
print(f"âœ… TensorFlow version: {tf.__version__}")


# ==============================================================================
# UPLOAD DEL SAVEDMODEL
# ==============================================================================

print("\n=== Upload saved_model.zip ===")
from google.colab import files
uploaded = files.upload()

# Descomprimir
!unzip -q saved_model.zip
!ls -lh saved_model/

print("âœ… SavedModel listo")


# ==============================================================================
# CONVERSIÃ“N
# ==============================================================================

print("\n=== ConversiÃ³n SavedModel â†’ TF.js ===")

import tensorflowjs as tfjs

tfjs.converters.convert_tf_saved_model(
    saved_model_dir='./saved_model',
    output_dir='./student_v1_fp16',
    quantization_dtype_map={'float': 'float16'}
)

print("âœ… ConversiÃ³n completada")


# ==============================================================================
# VERIFICAR RESULTADO
# ==============================================================================

!ls -lh student_v1_fp16/

import os
import glob

files_list = glob.glob('./student_v1_fp16/*')
total_size = sum(os.path.getsize(f) for f in files_list) / (1024 * 1024)

print(f"\nðŸ“¦ Archivos generados:")
for f in sorted(files_list):
    size = os.path.getsize(f) / (1024 * 1024)
    print(f"  - {os.path.basename(f):40s} ({size:6.2f} MB)")

print(f"\nðŸ“Š TamaÃ±o total: {total_size:.2f} MB")


# ==============================================================================
# DOWNLOAD
# ==============================================================================

print("\n=== Comprimiendo resultado ===")
!zip -q -r student_v1_fp16.zip student_v1_fp16

print("Descargando student_v1_fp16.zip...")
files.download('student_v1_fp16.zip')

print("\nâœ… DESCARGA COMPLETADA")
```

### Paso 4: Ejecutar y esperar

1. Hacer clic en el botÃ³n **â–¶ Ejecutar** (o presionar `Ctrl+Enter`)
2. Cuando pida "Choose Files", seleccionar `saved_model.zip`
3. Esperar 2-3 minutos (instalaciÃ³n + conversiÃ³n)
4. Al final descargarÃ¡ automÃ¡ticamente `student_v1_fp16.zip`

### Paso 5: Descomprimir y mover en local

```bash
# En tu mÃ¡quina local
cd /home/skanndar/SynologyDrive/local/aplantida/ml-training

# Descomprimir (ajusta la ruta donde se descargÃ³)
unzip ~/Downloads/student_v1_fp16.zip -d dist/models/

# Copiar metadata
cp dist/models/student_v1_fp16_manual/export_metadata.json \
   dist/models/student_v1_fp16/

# Verificar
ls -lh dist/models/student_v1_fp16/
```

DeberÃ­as ver:

```
dist/models/student_v1_fp16/
â”œâ”€â”€ model.json                        (~5 KB)
â”œâ”€â”€ group1-shard1of*.bin              (~15-20 MB cada uno)
â”œâ”€â”€ group1-shard2of*.bin
â”œâ”€â”€ group1-shard3of*.bin
â””â”€â”€ export_metadata.json              (~1 KB)
```

## SoluciÃ³n de Problemas

### Error: "No matching distribution found for tensorflow==2.13.1"

**Causa:** Google Colab ya no incluye TF 2.13.x

**SoluciÃ³n:** Usar el cÃ³digo arriba que usa la versiÃ³n preinstalada (2.16+)

### Error: "quantize_float16 not recognized"

**Causa:** Sintaxis cambiÃ³ en versiones recientes de tensorflowjs

**SoluciÃ³n:** Usar `quantization_dtype_map={'float': 'float16'}` en lugar de `--quantize_float16='*'`

### Error al descargar: "Failed - Forbidden"

**Causa:** Navegador bloqueÃ³ descarga automÃ¡tica

**SoluciÃ³n:** Hacer clic derecho en archivo â†’ Descargar en el panel izquierdo de Colab

### Archivo descargado demasiado pequeÃ±o

**Causa:** La conversiÃ³n fallÃ³ silenciosamente

**SoluciÃ³n:** Revisar salida de la celda, buscar errores en el log

## VerificaciÃ³n del Resultado

### Estructura esperada

```
student_v1_fp16/
â”œâ”€â”€ model.json                   # Graph definition (5-10 KB)
â”œâ”€â”€ group1-shard1of3.bin         # Weights part 1 (~20 MB)
â”œâ”€â”€ group1-shard2of3.bin         # Weights part 2 (~20 MB)
â””â”€â”€ group1-shard3of3.bin         # Weights part 3 (~10 MB)
```

**TamaÃ±o total esperado:** 50-70 MB (cuantizado a FP16)

### Verificar model.json

```bash
cat dist/models/student_v1_fp16/model.json | jq '.format'
# Output esperado: "graph-model"

cat dist/models/student_v1_fp16/model.json | jq '.modelTopology.node[0].name'
# Debe mostrar un nombre de nodo vÃ¡lido
```

### Test de carga en Node.js

```javascript
const tf = require('@tensorflow/tfjs-node');

async function test() {
  const model = await tf.loadGraphModel(
    'file://./dist/models/student_v1_fp16/model.json'
  );

  console.log('âœ… Model loaded successfully');
  console.log('Input shape:', model.inputs[0].shape);   // [null, 224, 224, 3]
  console.log('Output shape:', model.outputs[0].shape); // [null, 7120]

  // Test inference
  const dummyInput = tf.randomNormal([1, 224, 224, 3]);
  const output = model.predict(dummyInput);
  console.log('Inference output shape:', output.shape); // [1, 7120]

  tf.dispose([dummyInput, output]);
}

test().catch(console.error);
```

## ComparaciÃ³n con SavedModel

### TamaÃ±o

- **SavedModel:** ~51 MB (saved_model.pb)
- **TF.js (FP16):** ~50-60 MB (model.json + shards)
- **TF.js (FP32):** ~100-120 MB (sin cuantizaciÃ³n)

La diferencia es mÃ­nima porque ambos usan FP16.

### PrecisiÃ³n

El modelo TF.js debe tener la misma precisiÃ³n que el SavedModel (MAE < 0.01 en validaciÃ³n).

## PrÃ³ximos Pasos

Una vez tengas `dist/models/student_v1_fp16/` completo:

1. **Ver documentaciÃ³n de integraciÃ³n:**
   ```bash
   cat FRONTEND_INTEGRATION.md
   ```

2. **Copiar a frontend:**
   ```bash
   cp -r dist/models/student_v1_fp16 \
      /ruta/a/aplantidaFront/public/models/student_v1.0
   ```

3. **Actualizar cÃ³digo frontend:**
   Ver secciÃ³n Â§4 en [EXPORT_TFJS_PWA.md](aplantida-ml-training/EXPORT_TFJS_PWA.md#4---integraciÃ³n-en-frontend-pwa)

4. **Test en navegador:**
   ```javascript
   const model = await tf.loadGraphModel('/models/student_v1.0/model.json');
   console.log('Model loaded:', model);
   ```

## Referencias

- **SavedModel validado:** [dist/models/student_v1_fp16_manual/saved_model/](../dist/models/student_v1_fp16_manual/saved_model/)
- **Metadata:** [export_metadata.json](../dist/models/student_v1_fp16_manual/export_metadata.json)
- **ValidaciÃ³n PyTorchâ†”TF:** [export_validation.json](../results/student_finetune_v1/export_validation.json)
- **Threshold decision:** [EXPORT_TFJS_PWA.md Â§1.5](aplantida-ml-training/EXPORT_TFJS_PWA.md#15---decisiÃ³n-del-threshold-de-confianza)
- **Frontend integration:** [FRONTEND_INTEGRATION.md](FRONTEND_INTEGRATION.md)

## Script Automatizado (Opcional)

Alternativamente, usa el script Python que genera todo el cÃ³digo para ti:

```bash
# Ver el script completo
cat scripts/convert_to_tfjs_colab.py

# El script incluye:
# - InstalaciÃ³n automÃ¡tica de tensorflowjs
# - Upload de saved_model.zip
# - ConversiÃ³n con cuantizaciÃ³n FP16
# - VerificaciÃ³n de archivos
# - Download automÃ¡tico del resultado
```

Copia el contenido de `scripts/convert_to_tfjs_colab.py` en una celda de Colab y ejecÃºtalo.

## Tiempo Estimado

- **Upload (51 MB):** 1-2 minutos (depende de tu conexiÃ³n)
- **InstalaciÃ³n:** 30 segundos
- **ConversiÃ³n:** 1-2 minutos
- **Download (50-60 MB):** 1-2 minutos

**Total:** 5-8 minutos

---

**Ãšltima actualizaciÃ³n:** 24 de diciembre de 2025
**Estado:** Verificado con TensorFlow 2.17+ en Google Colab
